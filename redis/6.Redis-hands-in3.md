

# Redis Hands-in 3

> Redis On Kubernetes







# 1. [MR] Master Backup 중요성

Master Backup 여부에 따라 Master 재기동시  Data 유지 되는지를 확인해 보자.

Master 를 백업하지 않는 상태에서 재기동 하게 되면 Replica 까지 모두 초기화 된다.

이를 확인해 보자.



## 1) master backup 없이 재기동



### (1) 수행순서

1) MR Redis 설치 without PV
2) set 명령수행
3) Replica 에서 get 확인
4) Master down / 재기동 수행
5) Replica 에서 get 확인



### (2) 실습환경

터미널 2개를 준비하자.

* 터미널1 : ubuntu 내
* 터미널2 : redis-client pod - (replica용도)



### (3) [2번terminal] Replica 로 접속하여 get 확인

```sh

## redis-client 로 접근한다.
$ kubectl -n redis-mr exec -it deploy/redis-client -- bash

root@redis-client-9f57dc6d6-j578s:/data# 

# 1초에 한번씩 get 하자.
$ while true;do redis-cli -h ds-redis-replicas -a new1234 get a; sleep 1;echo; done;


```





### (4) [터미널1] Master down/restart

```sh
## redis-client 로 접근한다.
$ kubectl -n redis-mr get pod
NAME                           READY   STATUS    RESTARTS   AGE
ds-redis-master-0              1/1     Running   0          34m
ds-redis-replicas-0            1/1     Running   0          34m
ds-redis-replicas-1            1/1     Running   0          34m

# master pod down/restart
$ kubectl -n redis-mr delete pod ds-redis-master-0


# 확인
$ kubectl -n redis-mr get pod  -w
NAME                           READY   STATUS    RESTARTS   AGE
ds-redis-master-0              0/1     Running   0          5s
...
ds-redis-master-0              1/1     Running   0          20s


```





### (5) [터미널2] 결과 확인

```sh


"1"

"1"

Fri Mar  8 13:12:52 UTC 2024    # <-- 삭제
(nil)

```

* 결론
  * slave 로 접속하여 읽어들이는 value 가 초기화 되어 버렸다.
  * 이런 상황을 방지하기 위해서 반드시 MR 구조에서는 Master를 백업해야 한다.





## 2) master backup후 재기동



### (1) 수행순서

1) MR Redis 설치 with PV
2) set 명령수행
3) Replica 에서 get 확인
4) Master down / 재기동 수행
5) Replica 에서 get 확인



### (2) 실습환경

터미널3개를 준비하자.

* 터미널1 : ubuntu
* 터미널2 : redis-client pod - (master용도)
* 터미널3 : redis-client pod - (slave용도)



### (3) [터미널1] Redis 설치 with PV

#### 기존 Redis 제거

```sh

# 확인
$ helm -n redis-mr ls
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                             APP VERSION
ds-redis        redis-mr        1               2024-03-08 13:37:00.692463764 +0000 UTC deployed        redis-18.1                7.1     7.2.4



# Redis 삭제
$ helm -n redis-mr delete ds-redis


```



#### Redis 설치

```sh
## ubuntu에서...

# helm install
# master 1, replica 2 실행

# 설치
$ helm -n redis-mr install ds-redis bitnami/redis \
    --set global.redis.password=new1234 \
    --set image.registry=docker.io \
    --set master.persistence.enabled=true \
    --set master.persistence.size=1Gi \
    --set master.service.type=NodePort \
    --set master.service.nodePorts.redis=32300 \
    --set replica.replicaCount=2 \
    --set replica.persistence.enabled=false \
    --set replica.service.type=NodePort \
    --set replica.service.nodePorts.redis=32310

##
NAME: ds-redis
LAST DEPLOYED: Fri Mar  8 14:11:43 2024
NAMESPACE: redis-mr
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: redis
CHART VERSION: 18.17.1
APP VERSION: 7.2.4



# 설치목록 확인
$ helm -n redis-mr ls
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION
ds-redis        redis-mr        1               2024-03-08 13:37:00.692463764 +0000 UTC deployed        redis-18.17.1   7.2.4



# 확인
$ helm -n redis-mr status my-release
$ helm -n redis-mr get all my-release


```



#### pod / svc 확인

```sh


$ kubectl -n redis-mr get svc
NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
ds-redis-headless   ClusterIP   None            <none>        6379/TCP         47s
ds-redis-replicas   NodePort    10.43.239.194   <none>        6379:32310/TCP   47s
ds-redis-master     NodePort    10.43.217.35    <none>        6379:32300/TCP   47s


$ kubectl -n redis-mr get pod
NAME                           READY   STATUS    RESTARTS   AGE
ds-redis-master-0              1/1     Running   0          2m2s
ds-redis-replicas-0            1/1     Running   0          2m2s
ds-redis-replicas-1            1/1     Running   0          86s



# 약 1분 정도 소요됨 
```





#### statefulset  pvc 확인

```sh

$ kubectl -n redis-mr get pod ds-redis-master-0 -o yaml


apiVersion: v1
kind: Pod
metadata:
  name: ds-redis-master-0
  namespace: redis-mr
  ...
spec:
  containers:
  ...
    volumeMounts:
    - mountPath: /data                          # <-- backup 데이터가 존재하는 위치
      name: redis-data
      ...

  volumes:
  - name: redis-data
    persistentVolumeClaim:
      claimName: redis-data-ds-redis-master-0  # <-- pvc 확인
      ...
---

```



### (4) [터미널3] Replica접속 get

```sh
## ubuntu에서...

## redis-client 로 접근한다.
$ kubectl -n redis-mr exec -it deploy/redis-client -- bash

root@redis-client-9f57dc6d6-j578s:/data# 


# 1초에 한번씩 get 하자.
$ while true;do redis-cli -h ds-redis-replicas -a new1234 get a; sleep 1;echo; done;
(nil)

(nil)

# 현재는 아무런 데이터 가 없으므로 null 값이 리턴된다.

```





### (5) [터미널2] Master접속 set 

```sh
## ubuntu에서...


## redis-client 로 접근한다.
$ kubectl -n redis-mr exec -it deploy/redis-client -- bash

root@redis-client-9f57dc6d6-j578s:/data# 



# master connect
$ redis-cli -h ds-redis-master  -a new1234


## set 명령 수행
my-release-redis-master:6379> set a 1111
OK

my-release-redis-master:6379> set a 2222
OK

my-release-redis-master:6379> set a 3333
OK


# Master 에서 입력하면 Replica[터미널3]에서 바로 복제 되는 것을 확인할 수 있다.


$ exit

```



#### AOF 파일 확인

Master POD 로 접근하여 AOF 파일이 어떻게 쌓이는지 확인해보자.

반드시 Master POD 로 접근해야 한다.

```sh
## ubuntu에서...


## Master pod 내로 접근한다.
$ kubectl -n redis-mr exec -it pod/ds-redis-master-0 -- bash


# append only File 확인
$ cat /data/appendonlydir/appendonly.aof.1.incr.aof
*2
$6
SELECT
$1
0
*3
$3
set
$1
a
$4
1111
*3
$3
set
$1
a
$4
2222
*3
$3
set
$1
a
$4
3333


# file 을 확인해보면
# 우리가 입력한 명령어들이 append 되어 있다.

```

* AOF 파일 내용 확인
  * 모든 명령어 기록은 항상 * 로 시작하며 * 다음 숫자는 명령을 구성하고 있는 단어 갯수
  * $ 는 요소를 나타냄, $ 뒤 숫자는 요소의 글자수를 나타냄
  * 그 다음행은 명령자체가 기록됨





### (6) [터미널1] Master down/restart

```sh
## ubuntu에서...


## redis-client 로 접근한다.
$ kubectl -n redis-mr get pod
NAME                           READY   STATUS    RESTARTS   AGE
ds-redis-master-0              1/1     Running   0          5m20s
ds-redis-replicas-0            1/1     Running   0          5m20s
ds-redis-replicas-1            1/1     Running   0          4m49s


# Master pod down/restart
# Master pod delete
$ kubectl -n redis-mr delete pod ds-redis-master-0


# 확인
$ kubectl -n redis-mr get pod  -w
NAME                           READY   STATUS    RESTARTS   AGE
ds-redis-master-0              0/1     Running   0          5s
...
ds-redis-master-0              1/1     Running   0          20s


```





### (7) [터미널2] 결과 확인

```sh

"3333"

"3333"

```

* 결론

  * slave 로 접속하여 읽어들이는 value 가 초기화 되지 않고 유지 된다.

    



### (8) [터미널2] Master pod Data 확인

```sh
## ubuntu에서...


## master pod 내로 접근한다.
$ kubectl -n redis-mr exec -it pod/ds-redis-master-0 -- bash



# append only File 확인

$ cat /data/appendonlydir/appendonly.aof.1.incr.aof
*2
$6
SELECT
$1
0
*3
$3
set
$1
a
$4
1111
*3
$3
set
$1
a
$4
2222
*3
$3
set
$1
a
$4
3333
------

# master pod 가 재기동 되었음에도 이전 AOF 파일들이 그대로 존재한다.

```

* 결론
  * 안정적인 운영을 위해 Redis-MR 구조에서는 반드시 Master 를 백업하자.



### (9) Clean Up

```sh

# 1) helm
# helm 확인
$ helm -n redis-mr ls


# helm 삭제
$ helm -n redis-mr delete ds-redis



# 2) pvc
# pvc 확인
$ kubectl -n redis-mr get pvc
NAME                           STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
redis-data-ds-redis-master-0   Bound    pvc-c07f96f6-c128-4a35-be0f-80ebe52acfc1   1Gi        RWO            local-path     11m

# pvc 삭제
$ kubectl -n redis-mr delete pvc redis-data-ds-redis-master-0 


# 3) pv
# pv 확인
$ kubectl -n redis-mr get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                   STORAGECLASS   REASON   AGE
pvc-c07f96f6-c128-4a35-be0f-80ebe52acfc1   1Gi        RWO            Delete           Bound    redis-mr/redis-data-ds-redis-master-0   local-path              11m

# pvc 삭제
$ kubectl -n redis-mr delete pv pvc-c07f96f6-c128-4a35-be0f-80ebe52acfc1



# 4)
# 확인
$ kubectl -n redis-mr get all


```







# 2. [RC] FailOver Test



Master node 1개를 down 하여 Cluster 가 정상 작동하는지, Slave 가 Master 로 승격되는지 추이를 살펴 본다.



* 테스트 절차

```
1) Cluster node 중 master node down(pod 삭제)
2) cluster nodes 로 Master Node 상태 확인

```





## 1) Master node down



### (1) master node down

```sh
$ redis-cli -h my-release-redis-cluster -c -a new1234

# 확인
my-release-redis-cluster:6379> cluster nodes
9fa9dc6cab3398624df40713b4bc675b1322184c 10.42.0.129:6379@16379 myself,master - 0 1689167734000 3 connected 10923-16383
37ede9c99774fcdb6ad3b34f7d681061244fba93 10.42.0.128:6379@16379 master - 0 1689167736973 2 connected 5461-10922
bf04da290df7003c4dacb45cbdf2ac40d696663c 10.42.0.131:6379@16379 slave 9d6c30fdada95856e40e1634c51113a85dd50c53 0 1689167738983 1 connected
77b47a2e6cd38a19ce7b71eaf142b0ef87de16b9 10.42.0.132:6379@16379 slave 37ede9c99774fcdb6ad3b34f7d681061244fba93 0 1689167738000 2 connected
ff84e2066b155907cf0981f9c37bbc2686d8c880 10.42.0.130:6379@16379 slave 9fa9dc6cab3398624df40713b4bc675b1322184c 0 1689167737000 3 connected
9d6c30fdada95856e40e1634c51113a85dd50c53 10.42.0.127:6379@16379 master - 0 1689167737978 1 connected 0-5460


10.42.0.129:6379> get a
"1"

10.42.0.129:6379> get b
-> Redirected to slot [3300] located at 10.42.0.127:6379
"2"

10.42.0.127:6379>  get c
-> Redirected to slot [7365] located at 10.42.0.128:6379
"3"


# c key 가 존재하는 10.42.0.128(Master) 를 down 시켜 보자.
# 아마도 10.42.0.132(Slave) 가 Master 로 승격 될 것이다.

###
# down 시도
###



```



slave --> master 로 변경된 node log 를확인해 보자.

```sh
1:S 12 Jul 2023 13:18:41.965 # Connection with master lost.
1:S 12 Jul 2023 13:18:41.965 * Caching the disconnected master state.
1:S 12 Jul 2023 13:18:41.965 * Reconnecting to MASTER 10.42.0.128:6379
1:S 12 Jul 2023 13:18:41.965 * MASTER <-> REPLICA sync started
1:S 12 Jul 2023 13:18:41.965 # Error condition on socket for SYNC: Connection refused
1:S 12 Jul 2023 13:18:42.362 * Connecting to MASTER 10.42.0.128:6379
1:S 12 Jul 2023 13:18:42.362 * MASTER <-> REPLICA sync started

# 20초 이후 Cluster fail
1:S 12 Jul 2023 13:19:02.420 * FAIL message received from bf04da290df7003c4dacb45cbdf2ac40d696663c about 37ede9c99774fcdb6ad3b34f7d681061244fba93
1:S 12 Jul 2023 13:19:02.420 # Cluster state changed: fail
1:S 12 Jul 2023 13:19:02.518 # Start of election delayed for 532 milliseconds (rank #0, offset 400).
1:S 12 Jul 2023 13:19:03.121 # Starting a failover election for epoch 7.
1:S 12 Jul 2023 13:19:03.128 # Failover election won: I'm the new master.
1:S 12 Jul 2023 13:19:03.128 # configEpoch set to 7 after successful failover

# 여기서부터 Master 로 변경되었다.
1:M 12 Jul 2023 13:19:03.128 * Discarding previously cached master state.
1:M 12 Jul 2023 13:19:03.128 # Setting secondary replication ID to dabdb3cdaa7ad4a95b38120995ba3d7884c549d5, valid up to offset: 401. New replication ID is a362761f13e0ce91bce8f643f817d56fe0afbc36
1:M 12 Jul 2023 13:19:03.129 # Cluster state changed: ok

# cluster ok

```







### (2) redis-cli 확인



계속 get 명령 수행해보자.

```sh

10.42.0.128:6379>  get c
Error: Server closed the connection
10.42.0.128:6379>  get c
^[[A
Could not connect to Redis at 10.42.0.128:6379: No route to host
(34.46s)
not connected> get c
Could not connect to Redis at 10.42.0.128:6379: No route to host
(3.07s)


# 10.42.0.128 서버가 다운되어 있으므로 connection 이 close 되어 버렸다.


```



새로운 connection 으로 접근해보자.

```sh
$ redis-cli -h my-release-redis-cluster -c -a new1234

10.42.0.132:6379> cluster nodes
bf04da290df7003c4dacb45cbdf2ac40d696663c 10.42.0.131:6379@16379 slave 9d6c30fdada95856e40e1634c51113a85dd50c53 0 1689168015927 1 connected
37ede9c99774fcdb6ad3b34f7d681061244fba93 10.42.0.128:6379@16379 master,fail - 1689167922262 1689167919000 2 connected
9fa9dc6cab3398624df40713b4bc675b1322184c 10.42.0.129:6379@16379 master - 0 1689168017940 3 connected 10923-16383
77b47a2e6cd38a19ce7b71eaf142b0ef87de16b9 10.42.0.132:6379@16379 myself,master - 0 1689168016000 7 connected 5461-10922
9d6c30fdada95856e40e1634c51113a85dd50c53 10.42.0.127:6379@16379 master - 0 1689168017000 1 connected 0-5460
ff84e2066b155907cf0981f9c37bbc2686d8c880 10.42.0.130:6379@16379 slave 9fa9dc6cab3398624df40713b4bc675b1322184c 0 1689168016935 3 connected



```

10.42.0.132 node 가 slave 에서 master 로 승격되었다.

하지만 기존에 down된 node 는 fail 로 남아 있다.

get 명령을 수행해보자.

```sh
10.42.0.132:6379> get a
-> Redirected to slot [15495] located at 10.42.0.129:6379
"1"
10.42.0.129:6379>
10.42.0.129:6379> get b
-> Redirected to slot [3300] located at 10.42.0.127:6379
"2"
10.42.0.127:6379>
10.42.0.127:6379> get c
-> Redirected to slot [7365] located at 10.42.0.132:6379
"3"
```



새로운 connection 은 문제가 없다.

Fail Node 는 어떻게 정상화 시킬 수 있을까?  (task 1)

기존 connection 에서 Redis 가 정상화 되었을때 문제 없이 connect 되어야 하는데 어떻게 해결 할수 있을까?  (task 2)



#### [참고] redis-cli  지속 실행

```sh
## redis-client 로 접근
$ oc -n redis-poc exec -it deploy/redis-client -- bash

# data read 확인
$ redis-cli -h sa-redisin-redis-cluster -c -a new1234 get a
$ redis-cli -h sa-redisin-redis-cluster -c -a new1234 get b
$ redis-cli -h sa-redisin-redis-cluster -c -a new1234 get c


# 1초에 한번씩 get 실행
$ while true; do date; \
    redis-cli -h sa-redisin-redis-cluster -c -a new1234 get a; \
    redis-cli -h sa-redisin-redis-cluster -c -a new1234 get b; \
    redis-cli -h sa-redisin-redis-cluster -c -a new1234 get c; echo; sleep 1; done

```









### (3) python 테스트



```python

# redis set
rc.set("a", "python1")
rc.set("b", "python2")
rc.set("c", "python3")



# 1초에 한번씩 get 실행
from time import sleep

for i in range(10000):
    print(i)
    sleep(1)
    rc.get("a")
    rc.get("b")
    rc.get("c")
    

# down 발생시점에서 약 20초정도 이후 정상작동한다.

```









### (4) Fail Node 확인



#### pod not ready 확인

pod 를 확인해 보자.

```sh
$ krs get pod
NAME                            READY   STATUS    RESTARTS   AGE
python-7d59455985-scgxb         2/2     Running   0          3d8h
my-release-redis-cluster-2      1/1     Running   0          36m
my-release-redis-cluster-3      1/1     Running   0          36m
my-release-redis-cluster-4      1/1     Running   0          36m
my-release-redis-cluster-5      1/1     Running   0          36m
my-release-redis-cluster-0      1/1     Running   0          36m
redis-client-69dcc9c76d-g6sms   1/1     Running   0          35m
my-release-redis-cluster-1      0/1     Running   0          22m

```

down 이후 자동 재기동된 pod가 readiness 를 통과하지 못했다. 

원인이 무엇인지 확인해보자.



아래는 readinessprobe 명령이다.

```yaml
                                                                                                           │
│     readinessProbe:                                                                                                            │
│       exec:                                                                                                                    │
│         command:                                                                                                               │
│         - sh                                                                                                                   │
│         - -c                                                                                                                   │
│         - /scripts/ping_readiness_local.sh 1                                                                                   │
│       failureThreshold: 5                                                                                                      │
│       initialDelaySeconds: 5                                                                                                   │
│       periodSeconds: 5                                                                                                         │
│       successThreshold: 1                                                                                                      │
│       timeoutSeconds: 2  
```



ping_readiness_local.sh 값을 확인해보자.

```shell
$ cat /scripts/ping_readiness_local.sh
#!/bin/sh
set -e

REDIS_STATUS_FILE=/tmp/.redis_cluster_check
if [ ! -z "$REDIS_PASSWORD" ]; then export REDISCLI_AUTH=$REDIS_PASSWORD; fi;
response=$(
  timeout -s 15 $1 \
  redis-cli \
    -h localhost \
    -p $REDIS_PORT_NUMBER \
    ping
)
if [ "$?" -eq "124" ]; then
  echo "Timed out"
  exit 1
fi
if [ "$response" != "PONG" ]; then
  echo "$response"
  exit 1
fi
if [ ! -f "$REDIS_STATUS_FILE" ]; then
  response=$(
    timeout -s 15 $1 \
    redis-cli \
      -h localhost \
      -p $REDIS_PORT_NUMBER \
      CLUSTER INFO | grep cluster_state | tr -d '[:space:]'
  )
  if [ "$?" -eq "124" ]; then
    echo "Timed out"
    exit 1
  fi
  if [ "$response" != "cluster_state:ok" ]; then
    echo "$response"
    exit 1
  else
    touch "$REDIS_STATUS_FILE"
  fi

```





fail node 에서 확인해보자.

```sh

$ sh -c "/scripts/ping_readiness_local.sh 1"
cluster_state:fail

# 실패한다.



# 패스워드는 정상
$ echo $REDIS_PASSWORD
new1234

$ echo $REDIS_PORT_NUMBER
6379


# ping pong test
$ redis-cli \
    -h localhost \
    -p 6379 \
    ping
PONG


# cluster info 확인 1
$ redis-cli \
      -h localhost \
      -p $REDIS_PORT_NUMBER \
      CLUSTER INFO

cluster_state:fail
cluster_slots_assigned:0
cluster_slots_ok:0
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:1
cluster_size:0
cluster_current_epoch:0
cluster_my_epoch:0
cluster_stats_messages_sent:0
cluster_stats_messages_received:0
total_cluster_links_buffer_limit_exceeded:0


# cluster info 확인 2
$ redis-cli \
      -h localhost \
      -p $REDIS_PORT_NUMBER \
      CLUSTER INFO | grep cluster_state | tr -d '[:space:]'

cluster_state:fail



```



결국 cluster_state 가 실패하여 not ready 되었다.





#### container 시작 명령 확인



```yaml
  containers:
  - args:
    - |
      # Backwards compatibility change
      if ! [[ -f /opt/bitnami/redis/etc/redis.conf ]]; then
          echo COPYING FILE
          cp  /opt/bitnami/redis/etc/redis-default.conf /opt/bitnami/redis/etc/redis.conf
      fi
      pod_index=($(echo "$POD_NAME" | tr "-" "\n"))
      pod_index="${pod_index[-1]}"
      if [[ "$pod_index" == "0" ]]; then
        export REDIS_CLUSTER_CREATOR="yes"
        export REDIS_CLUSTER_REPLICAS="1"
      fi
      /opt/bitnami/scripts/redis-cluster/entrypoint.sh /opt/bitnami/scripts/redis-cluster/run.sh
    command:
    - /bin/bash
    - -c

```





#### Fail node 확인

```sh

10.42.0.132:6379> cluster nodes
bf04da290df7003c4dacb45cbdf2ac40d696663c 10.42.0.131:6379@16379 slave 9d6c30fdada95856e40e1634c51113a85dd50c53 0 1689169951000 1 connected
37ede9c99774fcdb6ad3b34f7d681061244fba93 10.42.0.128:6379@16379 master,fail - 1689167922262 1689167919000 2 connected
9fa9dc6cab3398624df40713b4bc675b1322184c 10.42.0.129:6379@16379 master - 0 1689169953754 3 connected 10923-16383
77b47a2e6cd38a19ce7b71eaf142b0ef87de16b9 10.42.0.132:6379@16379 myself,master - 0 1689169951000 7 connected 5461-10922
9d6c30fdada95856e40e1634c51113a85dd50c53 10.42.0.127:6379@16379 master - 0 1689169952749 1 connected 0-5460
ff84e2066b155907cf0981f9c37bbc2686d8c880 10.42.0.130:6379@16379 slave 9fa9dc6cab3398624df40713b4bc675b1322184c 0 1689169952000 3 connected

```





### (5) 결론

* slave 가 master 로 승격되어 서비스는 정상 작동한다.
* 재기동된 기존의 node 는 자동으로 slave 로 추가되지 않는다.
* 그러므로 수작업으로 추가작업 해야 한다.





## 2) Fail Over 처리

Fail node 를 추방하고 기존 node 는 slave node로 추가하는 작업을 수행한다.



참고: 

https://mozi.tistory.com/382



### (1) FailOver with meet-replicate



* 순서

```
1) forget 명령으로 해당노드를 group에서 제거한다.
2) meet 명령으로 node 추가
   - 일반적으로 master node 로 추가된다.  그러므로 slave 로 변경해 줘야 한다.
3) replicate 명령으로 slave 설정을 한다.
```



```sh
# 작업전
$ cluster nodes
12a06ae7cd0ae7efd267814e28a83ff7824b8178 10.42.0.170:6379@16379 master - 0 1689391983000 2 connected 5461-10922
95acfe21a64250fa3359eb10e5f9cd23d38ec36c 10.42.0.168:6379@16379 master - 0 1689391981000 7 connected 10923-16383
a2e3366d2310533a6cab5181afa197c93a5904a3 10.42.0.169:6379@16379 myself,master - 0 1689391982000 1 connected 0-5460
0da823d72181e684dfaf1b0c9cc9b58be96675ce 10.42.0.173:6379@16379 slave 95acfe21a64250fa3359eb10e5f9cd23d38ec36c 0 1689391983141 7 connected
217cf57cc8a39cac12dd9d614317ad55fe4c57e4 10.42.0.171:6379@16379 master,fail - 1689391538631 0 0 connected
b109ed74a0e639d34067d1bf78a860931d0ee941 10.42.0.172:6379@16379 slave a2e3366d2310533a6cab5181afa197c93a5904a3 0 1689391984146 1 connected


# 1) forget
## 모든 node 에서 1분이내에 수행해야 한다.
## 그렇지 않으면 gosship protocol에 의해서 원복된다.
$ 
redis-cli -h 10.42.0.170 -c -a $REDIS_PASSWORD cluster forget 217cf57cc8a39cac12dd9d614317ad55fe4c57e4
redis-cli -h 10.42.0.168 -c -a $REDIS_PASSWORD cluster forget 217cf57cc8a39cac12dd9d614317ad55fe4c57e4
redis-cli -h 10.42.0.169 -c -a $REDIS_PASSWORD cluster forget 217cf57cc8a39cac12dd9d614317ad55fe4c57e4
redis-cli -h 10.42.0.173 -c -a $REDIS_PASSWORD cluster forget 217cf57cc8a39cac12dd9d614317ad55fe4c57e4
redis-cli -h 10.42.0.172 -c -a $REDIS_PASSWORD cluster forget 217cf57cc8a39cac12dd9d614317ad55fe4c57e4


# 2) meet
##   재기동된 신규 pod의 IP를 확인한다.
$ redis-cli -h my-release-redis-cluster -a $REDIS_PASSWORD CLUSTER meet 10.42.0.174 6379



# 3) replicate
## REPLICAS <node-id>
##    Return <node-id> replicas.
## replicate 명령은 자신을 지정한 node-id의 슬레이브로 만드는 명령이다.
## 그러므로 replica node 로 login 한다음 master node-id 를 설정한다.
$ redis-cli -h localhost -c -a $REDIS_PASSWORD CLUSTER REPLICATE 12a06ae7cd0ae7efd267814e28a83ff7824b8178


# 작업후
$ cluster nodes
12a06ae7cd0ae7efd267814e28a83ff7824b8178 10.42.0.170:6379@16379 master - 0 1689391225000 2 connected 5461-10922
95acfe21a64250fa3359eb10e5f9cd23d38ec36c 10.42.0.168:6379@16379 master - 0 1689391224000 7 connected 10923-16383
a2e3366d2310533a6cab5181afa197c93a5904a3 10.42.0.169:6379@16379 myself,master - 0 1689391226000 1 connected 0-5460
0da823d72181e684dfaf1b0c9cc9b58be96675ce 10.42.0.173:6379@16379 slave 95acfe21a64250fa3359eb10e5f9cd23d38ec36c 0 1689391226830 7 connected
217cf57cc8a39cac12dd9d614317ad55fe4c57e4 10.42.0.171:6379@16379 master,fail - 1689390078333 0 0 connected
b109ed74a0e639d34067d1bf78a860931d0ee941 10.42.0.172:6379@16379 slave a2e3366d2310533a6cab5181afa197c93a5904a3 0 1689391224817 1 connected

```





### (2) FiailOver with add-node

* 순서

```
1) forget 명령으로 해당노드를 group에서 제거한다.
2) add-node 옵션으로 Slave Node 추가
```



```sh
# 샘플
$ redis-cli --cluster \
    add-node 127.0.0.1:7001 127.0.0.1:7000 \
    --cluster-slave 869859e396c881b3c26f2a386c1495235225b57b

# 작업전
$ cluster nodes
b109ed74a0e639d34067d1bf78a860931d0ee941 10.42.0.172:6379@16379 master - 0 1689469636411 8 connected 0-5460
95acfe21a64250fa3359eb10e5f9cd23d38ec36c 10.42.0.168:6379@16379 master - 0 1689469637000 7 connected 10923-16383
12a06ae7cd0ae7efd267814e28a83ff7824b8178 10.42.0.170:6379@16379 master - 0 1689469637417 2 connected 5461-10922
a2e3366d2310533a6cab5181afa197c93a5904a3 10.42.0.169:6379@16379 master,fail - 1689469515457 1689469511429 1 connected
da5aaba2df35da46204ff96eb4be853ccd507606 10.42.0.174:6379@16379 slave 12a06ae7cd0ae7efd267814e28a83ff7824b8178 0 1689469636000 2 connected
0da823d72181e684dfaf1b0c9cc9b58be96675ce 10.42.0.173:6379@16379 myself,slave 95acfe21a64250fa3359eb10e5f9cd23d38ec36c 0 1689469635000 7 connected


# 1) forget
## 모든 node 에서 1분이내에 수행해야 한다.
## 그렇지 않으면 gosship protocol에 의해서 원복된다.

$ 
redis-cli -h 10.42.0.170 -c -a $REDIS_PASSWORD cluster forget a2e3366d2310533a6cab5181afa197c93a5904a3
redis-cli -h 10.42.0.168 -c -a $REDIS_PASSWORD cluster forget a2e3366d2310533a6cab5181afa197c93a5904a3
redis-cli -h 10.42.0.169 -c -a $REDIS_PASSWORD cluster forget a2e3366d2310533a6cab5181afa197c93a5904a3
redis-cli -h 10.42.0.173 -c -a $REDIS_PASSWORD cluster forget a2e3366d2310533a6cab5181afa197c93a5904a3
redis-cli -h 10.42.0.172 -c -a $REDIS_PASSWORD cluster forget a2e3366d2310533a6cab5181afa197c93a5904a3

OK


# 2) add-node
## format
## [슬레이브 IP:PORT] , [클러스터 노드 IP:PORT], [--cluster-slave 옵션], [마스터가 될 노드 ID]

$ redis-cli -a new1234 \
    --cluster add-node 10.42.0.175:6379 10.42.0.172:6379 \
    --cluster-slave b109ed74a0e639d34067d1bf78a860931d0ee941


# 작업후
$ cluster nodes
ac04246dfccf850cbdf78565a52f131b1160233a 10.42.0.175:6379@16379 slave b109ed74a0e639d34067d1bf78a860931d0ee941 0 1689470266001 8 connected
0da823d72181e684dfaf1b0c9cc9b58be96675ce 10.42.0.173:6379@16379 slave 95acfe21a64250fa3359eb10e5f9cd23d38ec36c 0 1689470264000 7 connected
da5aaba2df35da46204ff96eb4be853ccd507606 10.42.0.174:6379@16379 slave 12a06ae7cd0ae7efd267814e28a83ff7824b8178 0 1689470264996 2 connected
b109ed74a0e639d34067d1bf78a860931d0ee941 10.42.0.172:6379@16379 myself,master - 0 1689470262000 8 connected 0-5460
12a06ae7cd0ae7efd267814e28a83ff7824b8178 10.42.0.170:6379@16379 master - 0 1689470264000 2 connected 5461-10922
95acfe21a64250fa3359eb10e5f9cd23d38ec36c 10.42.0.168:6379@16379 master - 0 1689470263990 7 connected 10923-16383

```






